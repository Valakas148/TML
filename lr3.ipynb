{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T17:28:08.275102Z",
     "start_time": "2024-11-14T17:28:07.082650Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('lr3/Shakespeare_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:39.404099Z",
     "start_time": "2024-11-07T16:59:39.165539Z"
    }
   },
   "id": "79f380bbd51bcceb",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   Dataline      Play  PlayerLinenumber ActSceneLine         Player  \\\n0         1  Henry IV               NaN          NaN            NaN   \n1         2  Henry IV               NaN          NaN            NaN   \n2         3  Henry IV               NaN          NaN            NaN   \n3         4  Henry IV               1.0        1.1.1  KING HENRY IV   \n4         5  Henry IV               1.0        1.1.2  KING HENRY IV   \n\n                                          PlayerLine  \n0                                              ACT I  \n1                       SCENE I. London. The palace.  \n2  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n3             So shaken as we are, so wan with care,  \n4         Find we a time for frighted peace to pant,  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataline</th>\n      <th>Play</th>\n      <th>PlayerLinenumber</th>\n      <th>ActSceneLine</th>\n      <th>Player</th>\n      <th>PlayerLine</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Henry IV</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ACT I</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Henry IV</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>SCENE I. London. The palace.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Henry IV</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Henry IV</td>\n      <td>1.0</td>\n      <td>1.1.1</td>\n      <td>KING HENRY IV</td>\n      <td>So shaken as we are, so wan with care,</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Henry IV</td>\n      <td>1.0</td>\n      <td>1.1.2</td>\n      <td>KING HENRY IV</td>\n      <td>Find we a time for frighted peace to pant,</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:39.437305Z",
     "start_time": "2024-11-07T16:59:39.405133Z"
    }
   },
   "id": "190d694399768ad2",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filtered_data = df[~df['PlayerLine'].str.contains(\"ACT|SCENE\", na=False)].copy()\n",
    "filtered_data['PlayerLine'] = filtered_data['PlayerLine'].str.lower()\n",
    "filtered_data['PlayerLine'] = filtered_data['PlayerLine'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:39.705482Z",
     "start_time": "2024-11-07T16:59:39.438313Z"
    }
   },
   "id": "db03f4c3ccd146",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(filtered_data, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:39.737654Z",
     "start_time": "2024-11-07T16:59:39.706498Z"
    }
   },
   "id": "9b678c039199670e",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'that is the question'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "\n",
    "class NgramModel:\n",
    "    def __init__(self, n=3, smoothing=1):\n",
    "        \"\"\"\n",
    "        Ініціалізація N-грамної моделі.\n",
    "        :param n: Розмір N-грами.\n",
    "        :param smoothing: Значення для Лапласового згладжування.\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "        self.smoothing = smoothing\n",
    "        self.ngram_counts = defaultdict(Counter)\n",
    "        self.context_counts = Counter()\n",
    "\n",
    "    def train(self, text):\n",
    "        \"\"\"\n",
    "        Навчання N-грамної моделі на заданому тексті.\n",
    "        :param text: Список токенізованих речень.\n",
    "        \"\"\"\n",
    "        for sentence in text:\n",
    "            tokens = ['<s>'] * (self.n - 1) + sentence + ['</s>']\n",
    "            for i in range(len(tokens) - self.n + 1):\n",
    "                ngram = tuple(tokens[i:i+self.n])\n",
    "                context = ngram[:-1]\n",
    "                token = ngram[-1]\n",
    "                self.ngram_counts[context][token] += 1\n",
    "                self.context_counts[context] += 1\n",
    "\n",
    "    def ngram_probability(self, context, token):\n",
    "        \"\"\"\n",
    "        Обчислення ймовірності N-грами з Лапласовим згладжуванням.\n",
    "        :param context: Контекст N-грами.\n",
    "        :param token: Токен N-грами.\n",
    "        :return: Ймовірність токена в даному контексті.\n",
    "        \"\"\"\n",
    "        count = self.ngram_counts[context][token]\n",
    "        total_count = self.context_counts[context]\n",
    "        vocab_size = len(self.ngram_counts)\n",
    "        return (count + self.smoothing) / (total_count + self.smoothing * vocab_size)\n",
    "\n",
    "    def generate_text(self, length=10, k=5):\n",
    "        \"\"\"\n",
    "        Генерація тексту на основі моделі з використанням top-k стратегії.\n",
    "        :param length: Довжина тексту, який треба згенерувати.\n",
    "        :param k: Кількість варіантів для вибору наступного токена.\n",
    "        :return: Згенерований текст.\n",
    "        \"\"\"\n",
    "        context = ('<s>',) * (self.n - 1)\n",
    "        result = list(context)\n",
    "        \n",
    "        for _ in range(length):\n",
    "            candidates = self.ngram_counts[context]\n",
    "            if not candidates:\n",
    "                break\n",
    "            top_k = Counter({token: self.ngram_probability(context, token) for token in candidates}).most_common(k)\n",
    "            tokens, probabilities = zip(*top_k)\n",
    "            next_token = np.random.choice(tokens, p=np.array(probabilities) / sum(probabilities))\n",
    "            result.append(next_token)\n",
    "            context = (*context[1:], next_token)\n",
    "            if next_token == '</s>':\n",
    "                break\n",
    "        \n",
    "        return ' '.join(result).replace('<s>', '').replace('</s>', '').strip()\n",
    "\n",
    "\n",
    "ngram_model = NgramModel(n=3)\n",
    "sample_text = [\n",
    "    \"to be or not to be\".split(),\n",
    "    \"that is the question\".split(),\n",
    "    \"whether tis nobler in the mind to suffer\".split()\n",
    "]\n",
    "ngram_model.train(sample_text)\n",
    "generated_text = ngram_model.generate_text(length=10, k=5)\n",
    "generated_text\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:39.834352Z",
     "start_time": "2024-11-07T16:59:39.738659Z"
    }
   },
   "id": "1e5004aec58dfe0",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{3: 77227.74040444875, 5: 223365.61041386478, 10: 228597.952037149}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NgramModelWithPerplexity(NgramModel):\n",
    "    def perplexity(self, test_text):\n",
    "        \"\"\"\n",
    "        Обчислення перплексії на тестовому тексті.\n",
    "        :param test_text: Список токенізованих речень для тестування.\n",
    "        :return: Значення перплексії.\n",
    "        \"\"\"\n",
    "        log_prob_sum = 0\n",
    "        word_count = 0\n",
    "        \n",
    "        for sentence in test_text:\n",
    "            tokens = ['<s>'] * (self.n - 1) + sentence + ['</s>']\n",
    "            for i in range(len(tokens) - self.n + 1):\n",
    "                ngram = tuple(tokens[i:i+self.n-1])\n",
    "                token = tokens[i+self.n-1]\n",
    "                prob = self.ngram_probability(ngram, token)\n",
    "                log_prob_sum += np.log(prob) if prob > 0 else float('-inf')\n",
    "                word_count += 1\n",
    "                \n",
    "        perplexity = np.exp(-log_prob_sum / word_count) if word_count > 0 else float('inf')\n",
    "        return perplexity\n",
    "\n",
    "train_text = [line.split() for line in train_data['PlayerLine'].dropna()]\n",
    "test_text = [line.split() for line in test_data['PlayerLine'].dropna()]\n",
    "def train_and_evaluate_ngram_models(train_text, test_text, n_values=[3, 5, 10]):\n",
    "    results = {}\n",
    "    \n",
    "    for n in n_values:\n",
    "        model = NgramModelWithPerplexity(n=n)\n",
    "        model.train(train_text)\n",
    "        perplexity = model.perplexity(test_text)\n",
    "        results[n] = perplexity\n",
    "    \n",
    "    return results\n",
    "model_results = train_and_evaluate_ngram_models(train_text, test_text, n_values=[3, 5, 10])\n",
    "model_results\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:47.099835Z",
     "start_time": "2024-11-07T16:59:39.837742Z"
    }
   },
   "id": "afd4cf8d8dff36ec",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'i have done'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NgramModelWithTopK(NgramModelWithPerplexity):\n",
    "    def generate_text_with_top_k(self, length=10, k=5):\n",
    "        \"\"\"\n",
    "        Генерація тексту з використанням top-k стратегії.\n",
    "        :param length: Довжина тексту, який треба згенерувати.\n",
    "        :param k: Кількість топ-варіантів для вибору наступного слова.\n",
    "        :return: Згенерований текст.\n",
    "        \"\"\"\n",
    "        context = ('<s>',) * (self.n - 1)\n",
    "        result = list(context)\n",
    "\n",
    "        for _ in range(length):\n",
    "            candidates = self.ngram_counts[context]\n",
    "            if not candidates:\n",
    "                break\n",
    "            top_k = Counter({token: self.ngram_probability(context, token) for token in candidates}).most_common(k)\n",
    "            tokens, probabilities = zip(*top_k)\n",
    "\n",
    "            probabilities = np.array(probabilities) / sum(probabilities)\n",
    "            next_token = np.random.choice(tokens, p=probabilities)\n",
    "\n",
    "            result.append(next_token)\n",
    "            context = (*context[1:], next_token)\n",
    "\n",
    "            if next_token == '</s>':\n",
    "                break\n",
    "\n",
    "        return ' '.join(result).replace('<s>', '').replace('</s>', '').strip()\n",
    "\n",
    "ngram_model_top_k = NgramModelWithTopK(n=3)\n",
    "ngram_model_top_k.train(train_text)\n",
    "\n",
    "generated_text_top_k = ngram_model_top_k.generate_text_with_top_k(length=20, k=5)\n",
    "generated_text_top_k\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:48.268511Z",
     "start_time": "2024-11-07T16:59:47.099835Z"
    }
   },
   "id": "6fac334e7f09f5d7",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "def generate_text(n, strategy, k, start_text, max_length):\n",
    "    model = NgramModelWithTopK(n=n)\n",
    "    model.train(train_text)  \n",
    "    \n",
    "    start_tokens = start_text.lower().split()\n",
    "    length = max_length\n",
    "    \n",
    "    if strategy == 'top-k':\n",
    "        generated_text = model.generate_text_with_top_k(length=length, k=k)\n",
    "    else:\n",
    "        generated_text = model.generate_text(length=length)  # Greedy\n",
    "\n",
    "    tokens = generated_text.split()\n",
    "    entropies = []\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        context = tuple(tokens[i:i+n-1])\n",
    "        token = tokens[i+n-1]\n",
    "        prob = model.ngram_probability(context, token)\n",
    "        entropies.append(-np.log(prob) if prob > 0 else float('inf'))\n",
    "    \n",
    "    avg_entropy = np.mean(entropies) if entropies else float('inf')\n",
    "    return generated_text, avg_entropy\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Генерація тексту за допомогою N-грамної моделі\")\n",
    "    n = gr.Slider(3, 10, step=1, label=\"Виберіть N для моделі\", value=3)\n",
    "    strategy = gr.Radio([\"greedy\", \"top-k\"], label=\"Виберіть стратегію генерації\")\n",
    "    k = gr.Slider(1, 20, step=1, label=\"Виберіть значення k для top-k стратегії\", value=5)\n",
    "    start_text = gr.Textbox(label=\"Початковий текст\")\n",
    "    max_length = gr.Slider(5, 50, step=1, label=\"Максимальна довжина згенерованого тексту\", value=20)\n",
    "    \n",
    "    generate_button = gr.Button(\"Згенерувати текст\")\n",
    "    output_text = gr.Textbox(label=\"Згенерований текст\")\n",
    "    entropy = gr.Number(label=\"Ентропія згенерованого тексту\")\n",
    "    \n",
    "    generate_button.click(generate_text, inputs=[n, strategy, k, start_text, max_length], outputs=[output_text, entropy])\n",
    "\n",
    "demo.launch()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:55.226975Z",
     "start_time": "2024-11-07T16:59:48.268511Z"
    }
   },
   "id": "9cf2408a1baf2853",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "to be or"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ff130e96cbf798d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "wherefore art thou"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fad93cb023355a79"
  },
  {
   "cell_type": "markdown",
   "source": [
    "all the world's a stage"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69c573d179bc3d5b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "love looks not"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2105842979ce9c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:55.229728Z",
     "start_time": "2024-11-07T16:59:55.228053Z"
    }
   },
   "id": "be41e5a2e8fdd242",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "abf32841408b38de"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.lm import Laplace\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.util import ngrams\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:57.684061Z",
     "start_time": "2024-11-07T16:59:55.229728Z"
    }
   },
   "id": "381c089f3f7974b0",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_text_tokens = [list(line) for line in train_text]\n",
    "test_text_tokens = [list(line) for line in test_text]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:57.921352Z",
     "start_time": "2024-11-07T16:59:57.685074Z"
    }
   },
   "id": "2ded2d1a3c0661df",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:57.938900Z",
     "start_time": "2024-11-07T16:59:57.937096Z"
    }
   },
   "id": "38cbdc0e1abb9dd",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import nltk\n",
    "from nltk.lm import Laplace\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.util import ngrams\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:57.948149Z",
     "start_time": "2024-11-07T16:59:57.943897Z"
    }
   },
   "id": "60e0d650c56d3e40",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_ngram_model(n, train_text_tokens):\n",
    "    train_data, padded_vocab = padded_everygram_pipeline(n, train_text_tokens)\n",
    "    model = Laplace(n)\n",
    "    model.fit(train_data, padded_vocab)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:57.952635Z",
     "start_time": "2024-11-07T16:59:57.949156Z"
    }
   },
   "id": "e11e8591652ea5e2",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_text(model, n, start_text, max_length=15, strategy=\"top-k\", k=5):\n",
    "    context = start_text.split()\n",
    "    generated = context.copy()\n",
    "    entropies = []\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        context_ngram = tuple(context[-(n-1):]) if len(context) >= n - 1 else tuple(context)\n",
    "        \n",
    "        if strategy == \"greedy\":\n",
    "            next_word = model.generate(text_seed=context_ngram)\n",
    "        elif strategy == \"top-k\":\n",
    "            candidates = [(word, model.score(word, context_ngram)) for word in model.vocab]\n",
    "            candidates = sorted(candidates, key=lambda x: x[1], reverse=True)[:k]\n",
    "            if not candidates:\n",
    "                break\n",
    "            words, probabilities = zip(*candidates)\n",
    "            probabilities = np.array(probabilities) / sum(probabilities)\n",
    "            next_word = np.random.choice(words, p=probabilities)\n",
    "        \n",
    "        if next_word == '</s>':\n",
    "            break\n",
    "        generated.append(next_word)\n",
    "        context.append(next_word)\n",
    "        \n",
    "        prob = model.score(next_word, context_ngram)\n",
    "        if prob > 0:\n",
    "            entropies.append(-np.log(prob))\n",
    "    \n",
    "    avg_entropy = np.mean(entropies) if entropies else float('inf')\n",
    "    return ' '.join(generated), avg_entropy\n",
    "\n",
    "train_text_tokens = [list(line.split()) for line in [\"to be or not to be\", \"that is the question\"]]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:57.967794Z",
     "start_time": "2024-11-07T16:59:57.953643Z"
    }
   },
   "id": "f55836fcde655b1",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradio_app(start_text, n, max_length, strategy, k):\n",
    "    model = train_ngram_model(n, train_text_tokens)\n",
    "    generated_text, avg_entropy = generate_text(model, n, start_text, max_length, strategy, k)\n",
    "    return generated_text, avg_entropy\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Генерація тексту за допомогою N-грамної моделі\")\n",
    "    start_text = gr.Textbox(label=\"Початковий текст\")\n",
    "    n = gr.Slider(3, 10, step=1, label=\"Виберіть N для моделі\", value=3)\n",
    "    max_length = gr.Slider(5, 50, step=1, label=\"Максимальна довжина згенерованого тексту\", value=20)\n",
    "    strategy = gr.Radio([\"greedy\", \"top-k\"], label=\"Виберіть стратегію генерації\")\n",
    "    k = gr.Slider(1, 20, step=1, label=\"Виберіть значення k для top-k стратегії\", value=5)\n",
    "    \n",
    "    generate_button = gr.Button(\"Згенерувати текст\")\n",
    "    output_text = gr.Textbox(label=\"Згенерований текст\")\n",
    "    entropy = gr.Number(label=\"Ентропія згенерованого тексту\")\n",
    "    \n",
    "    generate_button.click(gradio_app, inputs=[start_text, n, max_length, strategy, k], outputs=[output_text, entropy])\n",
    "\n",
    "demo.launch()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:58.366010Z",
     "start_time": "2024-11-07T16:59:57.968802Z"
    }
   },
   "id": "414ba73355fac883",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Варіант 3 Тільки текст"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85977eb97ddd0765"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ce3feff480acb5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Oleg_PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "import random\n",
    "from nltk.lm import Laplace\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "nltk.download('punkt_tab')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T17:45:27.691649Z",
     "start_time": "2024-11-14T17:45:20.677598Z"
    }
   },
   "id": "773f5b62ee77309b",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file_path = 'lr3/alllines.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T17:30:16.956925Z",
     "start_time": "2024-11-14T17:30:16.938479Z"
    }
   },
   "id": "2614c4d48f8f568e",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filtered_lines = []\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if not (line.startswith(\"ACT\") or line.startswith(\"SCENE\") or \"Enter\" in line):\n",
    "        filtered_lines.append(line)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T17:30:16.994148Z",
     "start_time": "2024-11-14T17:30:16.956925Z"
    }
   },
   "id": "18cb6ff6c2c8cb74",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text = ' '.join(filtered_lines)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T17:30:17.002678Z",
     "start_time": "2024-11-14T17:30:16.995429Z"
    }
   },
   "id": "245d01da6e864891",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T17:30:18.019160Z",
     "start_time": "2024-11-14T17:30:17.003689Z"
    }
   },
   "id": "7ef141df5ba4b489",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "processed_sentences = []\n",
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence.lower())\n",
    "    words = [re.sub(r'[^\\w\\s]', '', word) for word in words if word.isalpha()] \n",
    "    if words:  \n",
    "        processed_sentences.append(words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T17:30:22.831228Z",
     "start_time": "2024-11-14T17:30:18.020161Z"
    }
   },
   "id": "63a2821c2140244e",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['act', 'i', 'scene', 'london']\n",
      "['the', 'palace']\n",
      "['so', 'shaken', 'as', 'we', 'are', 'so', 'wan', 'with', 'care', 'find', 'we', 'a', 'time', 'for', 'frighted', 'peace', 'to', 'pant', 'and', 'breathe', 'accents', 'of', 'new', 'broils', 'to', 'be', 'commenced', 'in', 'strands', 'afar', 'remote']\n",
      "['no', 'more', 'the', 'thirsty', 'entrance', 'of', 'this', 'soil', 'shall', 'daub', 'her', 'lips', 'with', 'her', 'own', 'children', 'blood', 'nor', 'more', 'shall', 'trenching', 'war', 'channel', 'her', 'fields', 'nor', 'bruise', 'her', 'flowerets', 'with', 'the', 'armed', 'hoofs', 'of', 'hostile', 'paces', 'those', 'opposed', 'eyes', 'which', 'like', 'the', 'meteors', 'of', 'a', 'troubled', 'heaven', 'all', 'of', 'one', 'nature', 'of', 'one', 'substance', 'bred', 'did', 'lately', 'meet', 'in', 'the', 'intestine', 'shock', 'and', 'furious', 'close', 'of', 'civil', 'butchery', 'shall', 'now', 'in', 'mutual', 'ranks', 'march', 'all', 'one', 'way', 'and', 'be', 'no', 'more', 'opposed', 'against', 'acquaintance', 'kindred', 'and', 'allies', 'the', 'edge', 'of', 'war', 'like', 'an', 'knife', 'no', 'more', 'shall', 'cut', 'his', 'master']\n",
      "['therefore', 'friends', 'as', 'far', 'as', 'to', 'the', 'sepulchre', 'of', 'christ', 'whose', 'soldier', 'now', 'under', 'whose', 'blessed', 'cross', 'we', 'are', 'impressed', 'and', 'engaged', 'to', 'fight', 'forthwith', 'a', 'power', 'of', 'english', 'shall', 'we', 'levy', 'whose', 'arms', 'were', 'moulded', 'in', 'their', 'mothers', 'womb', 'to', 'chase', 'these', 'pagans', 'in', 'those', 'holy', 'fields', 'over', 'whose', 'acres', 'walk', 'those', 'blessed', 'feet', 'which', 'fourteen', 'hundred', 'years', 'ago', 'were', 'nail', 'for', 'our', 'advantage', 'on', 'the', 'bitter', 'cross']\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(processed_sentences[i])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T17:30:22.835442Z",
     "start_time": "2024-11-14T17:30:22.831228Z"
    }
   },
   "id": "d77d238a1050c43",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_sentences, test_sentences = train_test_split(processed_sentences, test_size=0.2, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T17:33:30.137504Z",
     "start_time": "2024-11-14T17:33:30.119021Z"
    }
   },
   "id": "4d3407ab9a27d1ee",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_ngram_model(n, train_sentences):\n",
    "    train_data, vocab = padded_everygram_pipeline(n, train_sentences)\n",
    "    model = Laplace(n)\n",
    "    model.fit(train_data, vocab)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T17:33:55.536624Z",
     "start_time": "2024-11-14T17:33:55.532730Z"
    }
   },
   "id": "2be961414f059c66",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Навчання 3-грамної моделі...\n",
      "3-грамна модель навчена.\n",
      "Навчання 5-грамної моделі...\n",
      "5-грамна модель навчена.\n",
      "Навчання 10-грамної моделі...\n",
      "10-грамна модель навчена.\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "for n in [3, 5, 10]:\n",
    "    print(f\"Навчання {n}-грамної моделі...\")\n",
    "    models[n] = train_ngram_model(n, train_sentences)\n",
    "    print(f\"{n}-грамна модель навчена.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T17:35:29.368194Z",
     "start_time": "2024-11-14T17:33:56.212410Z"
    }
   },
   "id": "5a6adacd9c823a12",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_sentences, n):\n",
    "    total_log_prob = 0\n",
    "    word_count = 0\n",
    "    entropies = []\n",
    "    \n",
    "    for sentence in test_sentences:\n",
    "        # Генерація n-грам для поточного речення\n",
    "        ngrams = list(nltk.ngrams(['<s>'] * (n - 1) + sentence + ['</s>'], n))\n",
    "        \n",
    "        for ngram in ngrams:\n",
    "            context = ngram[:-1]\n",
    "            word = ngram[-1]\n",
    "            prob = model.score(word, context)\n",
    "            log_prob = np.log(prob) if prob > 0 else float('-inf')\n",
    "            total_log_prob += log_prob\n",
    "            entropies.append(-log_prob if prob > 0 else 0)\n",
    "            word_count += 1\n",
    "    \n",
    "    # Обчислення перплексії\n",
    "    perplexity = np.exp(-total_log_prob / word_count) if word_count > 0 else float('inf')\n",
    "    # Середня ентропія\n",
    "    avg_entropy = np.mean(entropies) if entropies else float('inf')\n",
    "    return perplexity, avg_entropy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T17:38:23.179090Z",
     "start_time": "2024-11-14T17:38:23.174347Z"
    }
   },
   "id": "8b2d00497058a272",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оцінка 3-грамної моделі...\n",
      "3-грамна модель: Перплексія = 9596.57301883139, Ентропія = 9.169161336516845\n",
      "Оцінка 5-грамної моделі...\n",
      "5-грамна модель: Перплексія = 13225.561769508507, Ентропія = 9.489906733652935\n",
      "Оцінка 10-грамної моделі...\n",
      "10-грамна модель: Перплексія = 13301.64022190348, Ентропія = 9.495642631543033\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = {}\n",
    "for n, model in models.items():\n",
    "    print(f\"Оцінка {n}-грамної моделі...\")\n",
    "    perplexity, avg_entropy = evaluate_model(model, test_sentences, n)\n",
    "    evaluation_results[n] = {'perplexity': perplexity, 'entropy': avg_entropy}\n",
    "    print(f\"{n}-грамна модель: Перплексія = {perplexity}, Ентропія = {avg_entropy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T17:38:29.896202Z",
     "start_time": "2024-11-14T17:38:24.167908Z"
    }
   },
   "id": "eb4d072fcdbd0f4",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_text(model, n, start_text, max_length=15, strategy=\"top-k\", k=5):\n",
    "    context = start_text.split()\n",
    "    generated_text = context.copy()\n",
    "    entropies = []\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        context_ngram = tuple(context[-(n-1):]) if len(context) >= n - 1 else tuple(context)\n",
    "        \n",
    "        if strategy == \"greedy\":\n",
    "            next_word = model.generate(text_seed=context_ngram)\n",
    "        elif strategy == \"top-k\":\n",
    "            candidates = [(word, model.score(word, context_ngram)) for word in model.vocab]\n",
    "            candidates = sorted(candidates, key=lambda x: x[1], reverse=True)[:k]\n",
    "            if not candidates:\n",
    "                break\n",
    "            words, probabilities = zip(*candidates)\n",
    "            probabilities = np.array(probabilities) / sum(probabilities)\n",
    "            next_word = np.random.choice(words, p=probabilities)\n",
    "        \n",
    "        if next_word == '</s>':\n",
    "            break\n",
    "        generated_text.append(next_word)\n",
    "        context.append(next_word)\n",
    "        \n",
    "        \n",
    "        prob = model.score(next_word, context_ngram)\n",
    "        if prob > 0:\n",
    "            entropies.append(-np.log(prob))\n",
    "    \n",
    "    avg_entropy = np.mean(entropies) if entropies else float('inf')\n",
    "    return ' '.join(generated_text), avg_entropy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T17:45:04.717631Z",
     "start_time": "2024-11-14T17:45:04.711557Z"
    }
   },
   "id": "700dc439cd78757d",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T17:45:05.912273Z",
     "start_time": "2024-11-14T17:45:05.910576Z"
    }
   },
   "id": "b93f959d610b079b",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Створення Gradio інтерфейсу\n",
    "def gradio_app(start_text, n, max_length, strategy, k):\n",
    "    model = train_ngram_model(n, train_sentences)\n",
    "    generated_text, avg_entropy = generate_text(model, n, start_text, max_length, strategy, k)\n",
    "    return generated_text, avg_entropy\n",
    "\n",
    "# Налаштування інтерфейсу\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Генерація тексту за допомогою N-грамної моделі\")\n",
    "    start_text = gr.Textbox(label=\"Початковий текст\")\n",
    "    n = gr.Slider(3, 10, step=1, label=\"Виберіть N для моделі\", value=3)\n",
    "    max_length = gr.Slider(5, 50, step=1, label=\"Максимальна довжина згенерованого тексту\", value=20)\n",
    "    strategy = gr.Radio([\"greedy\", \"top-k\"], label=\"Виберіть стратегію генерації\")\n",
    "    k = gr.Slider(1, 20, step=1, label=\"Виберіть значення k для top-k стратегії\", value=5)\n",
    "    \n",
    "    generate_button = gr.Button(\"Згенерувати текст\")\n",
    "    output_text = gr.Textbox(label=\"Згенерований текст\")\n",
    "    entropy = gr.Number(label=\"Ентропія згенерованого тексту\")\n",
    "    \n",
    "    generate_button.click(gradio_app, inputs=[start_text, n, max_length, strategy, k], outputs=[output_text, entropy])\n",
    "\n",
    "# Запуск Gradio демо\n",
    "demo.launch()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T17:45:45.096737Z",
     "start_time": "2024-11-14T17:45:44.068121Z"
    }
   },
   "id": "6804d29983ea9dd",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "91c57e158aa76b90"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
