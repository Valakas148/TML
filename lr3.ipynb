{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:05:13.742760Z",
     "start_time": "2024-11-06T17:05:13.740063Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('lr3/Shakespeare_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:05:14.058592Z",
     "start_time": "2024-11-06T17:05:13.808906Z"
    }
   },
   "id": "79f380bbd51bcceb",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   Dataline      Play  PlayerLinenumber ActSceneLine         Player  \\\n0         1  Henry IV               NaN          NaN            NaN   \n1         2  Henry IV               NaN          NaN            NaN   \n2         3  Henry IV               NaN          NaN            NaN   \n3         4  Henry IV               1.0        1.1.1  KING HENRY IV   \n4         5  Henry IV               1.0        1.1.2  KING HENRY IV   \n\n                                          PlayerLine  \n0                                              ACT I  \n1                       SCENE I. London. The palace.  \n2  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n3             So shaken as we are, so wan with care,  \n4         Find we a time for frighted peace to pant,  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataline</th>\n      <th>Play</th>\n      <th>PlayerLinenumber</th>\n      <th>ActSceneLine</th>\n      <th>Player</th>\n      <th>PlayerLine</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Henry IV</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ACT I</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Henry IV</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>SCENE I. London. The palace.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Henry IV</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Henry IV</td>\n      <td>1.0</td>\n      <td>1.1.1</td>\n      <td>KING HENRY IV</td>\n      <td>So shaken as we are, so wan with care,</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Henry IV</td>\n      <td>1.0</td>\n      <td>1.1.2</td>\n      <td>KING HENRY IV</td>\n      <td>Find we a time for frighted peace to pant,</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:05:14.151193Z",
     "start_time": "2024-11-06T17:05:14.059596Z"
    }
   },
   "id": "190d694399768ad2",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filtered_data = df[~df['PlayerLine'].str.contains(\"ACT|SCENE\", na=False)].copy()\n",
    "filtered_data['PlayerLine'] = filtered_data['PlayerLine'].str.lower()\n",
    "filtered_data['PlayerLine'] = filtered_data['PlayerLine'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:05:14.513609Z",
     "start_time": "2024-11-06T17:05:14.152278Z"
    }
   },
   "id": "db03f4c3ccd146",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(filtered_data, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:05:14.544187Z",
     "start_time": "2024-11-06T17:05:14.515611Z"
    }
   },
   "id": "9b678c039199670e",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'whether tis nobler in the mind to suffer'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "\n",
    "class NgramModel:\n",
    "    def __init__(self, n=3, smoothing=1):\n",
    "        \"\"\"\n",
    "        Ініціалізація N-грамної моделі.\n",
    "        :param n: Розмір N-грами.\n",
    "        :param smoothing: Значення для Лапласового згладжування.\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "        self.smoothing = smoothing\n",
    "        self.ngram_counts = defaultdict(Counter)\n",
    "        self.context_counts = Counter()\n",
    "\n",
    "    def train(self, text):\n",
    "        \"\"\"\n",
    "        Навчання N-грамної моделі на заданому тексті.\n",
    "        :param text: Список токенізованих речень.\n",
    "        \"\"\"\n",
    "        for sentence in text:\n",
    "            tokens = ['<s>'] * (self.n - 1) + sentence + ['</s>']\n",
    "            for i in range(len(tokens) - self.n + 1):\n",
    "                ngram = tuple(tokens[i:i+self.n])\n",
    "                context = ngram[:-1]\n",
    "                token = ngram[-1]\n",
    "                self.ngram_counts[context][token] += 1\n",
    "                self.context_counts[context] += 1\n",
    "\n",
    "    def ngram_probability(self, context, token):\n",
    "        \"\"\"\n",
    "        Обчислення ймовірності N-грами з Лапласовим згладжуванням.\n",
    "        :param context: Контекст N-грами.\n",
    "        :param token: Токен N-грами.\n",
    "        :return: Ймовірність токена в даному контексті.\n",
    "        \"\"\"\n",
    "        count = self.ngram_counts[context][token]\n",
    "        total_count = self.context_counts[context]\n",
    "        vocab_size = len(self.ngram_counts)\n",
    "        return (count + self.smoothing) / (total_count + self.smoothing * vocab_size)\n",
    "\n",
    "    def generate_text(self, length=10, k=5):\n",
    "        \"\"\"\n",
    "        Генерація тексту на основі моделі з використанням top-k стратегії.\n",
    "        :param length: Довжина тексту, який треба згенерувати.\n",
    "        :param k: Кількість варіантів для вибору наступного токена.\n",
    "        :return: Згенерований текст.\n",
    "        \"\"\"\n",
    "        context = ('<s>',) * (self.n - 1)\n",
    "        result = list(context)\n",
    "        \n",
    "        for _ in range(length):\n",
    "            candidates = self.ngram_counts[context]\n",
    "            if not candidates:\n",
    "                break\n",
    "            # Отримуємо top-k варіанти\n",
    "            top_k = Counter({token: self.ngram_probability(context, token) for token in candidates}).most_common(k)\n",
    "            tokens, probabilities = zip(*top_k)\n",
    "            next_token = np.random.choice(tokens, p=np.array(probabilities) / sum(probabilities))\n",
    "            result.append(next_token)\n",
    "            context = (*context[1:], next_token)\n",
    "            if next_token == '</s>':\n",
    "                break\n",
    "        \n",
    "        return ' '.join(result).replace('<s>', '').replace('</s>', '').strip()\n",
    "\n",
    "# Ініціалізація триграмної моделі для прикладу\n",
    "ngram_model = NgramModel(n=3)\n",
    "\n",
    "# Демонстрація тренування моделі на невеликому прикладі\n",
    "sample_text = [\n",
    "    \"to be or not to be\".split(),\n",
    "    \"that is the question\".split(),\n",
    "    \"whether tis nobler in the mind to suffer\".split()\n",
    "]\n",
    "\n",
    "# Тренуємо модель на прикладі\n",
    "ngram_model.train(sample_text)\n",
    "\n",
    "# Приклад генерації тексту на основі навченої моделі\n",
    "generated_text = ngram_model.generate_text(length=10, k=5)\n",
    "generated_text\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:05:14.559026Z",
     "start_time": "2024-11-06T17:05:14.545194Z"
    }
   },
   "id": "1e5004aec58dfe0",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{3: 77227.74040444875, 5: 223365.61041386478, 10: 228597.952037149}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NgramModelWithPerplexity(NgramModel):\n",
    "    def perplexity(self, test_text):\n",
    "        \"\"\"\n",
    "        Обчислення перплексії на тестовому тексті.\n",
    "        :param test_text: Список токенізованих речень для тестування.\n",
    "        :return: Значення перплексії.\n",
    "        \"\"\"\n",
    "        log_prob_sum = 0\n",
    "        word_count = 0\n",
    "        \n",
    "        for sentence in test_text:\n",
    "            tokens = ['<s>'] * (self.n - 1) + sentence + ['</s>']\n",
    "            for i in range(len(tokens) - self.n + 1):\n",
    "                ngram = tuple(tokens[i:i+self.n-1])\n",
    "                token = tokens[i+self.n-1]\n",
    "                prob = self.ngram_probability(ngram, token)\n",
    "                log_prob_sum += np.log(prob) if prob > 0 else float('-inf')\n",
    "                word_count += 1\n",
    "\n",
    "        # Перплексія: експонента від -суми логарифмів ймовірностей, поділена на кількість слів\n",
    "        perplexity = np.exp(-log_prob_sum / word_count) if word_count > 0 else float('inf')\n",
    "        return perplexity\n",
    "\n",
    "# Підготовка тексту для тренування і тестування\n",
    "train_text = [line.split() for line in train_data['PlayerLine'].dropna()]\n",
    "test_text = [line.split() for line in test_data['PlayerLine'].dropna()]\n",
    "\n",
    "# Функція для тренування моделей з різними значеннями n та обчислення перплексії\n",
    "def train_and_evaluate_ngram_models(train_text, test_text, n_values=[3, 5, 10]):\n",
    "    results = {}\n",
    "    \n",
    "    for n in n_values:\n",
    "        model = NgramModelWithPerplexity(n=n)\n",
    "        model.train(train_text)\n",
    "        perplexity = model.perplexity(test_text)\n",
    "        results[n] = perplexity\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Навчання моделей для n = 3, 5, 10 та обчислення перплексії\n",
    "model_results = train_and_evaluate_ngram_models(train_text, test_text, n_values=[3, 5, 10])\n",
    "model_results\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:05:22.295295Z",
     "start_time": "2024-11-06T17:05:14.560032Z"
    }
   },
   "id": "afd4cf8d8dff36ec",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'to be'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NgramModelWithTopK(NgramModelWithPerplexity):\n",
    "    def generate_text_with_top_k(self, length=10, k=5):\n",
    "        \"\"\"\n",
    "        Генерація тексту з використанням top-k стратегії.\n",
    "        :param length: Довжина тексту, який треба згенерувати.\n",
    "        :param k: Кількість топ-варіантів для вибору наступного слова.\n",
    "        :return: Згенерований текст.\n",
    "        \"\"\"\n",
    "        context = ('<s>',) * (self.n - 1)\n",
    "        result = list(context)\n",
    "\n",
    "        for _ in range(length):\n",
    "            candidates = self.ngram_counts[context]\n",
    "            if not candidates:\n",
    "                break\n",
    "            # Обчислюємо ймовірності для кожного можливого наступного слова в контексті\n",
    "            top_k = Counter({token: self.ngram_probability(context, token) for token in candidates}).most_common(k)\n",
    "            tokens, probabilities = zip(*top_k)\n",
    "\n",
    "            # Нормалізуємо ймовірності і вибираємо наступний токен на основі розподілу ймовірностей\n",
    "            probabilities = np.array(probabilities) / sum(probabilities)\n",
    "            next_token = np.random.choice(tokens, p=probabilities)\n",
    "\n",
    "            result.append(next_token)\n",
    "            context = (*context[1:], next_token)\n",
    "\n",
    "            if next_token == '</s>':\n",
    "                break\n",
    "\n",
    "        return ' '.join(result).replace('<s>', '').replace('</s>', '').strip()\n",
    "\n",
    "# Демонстрація використання top-k стратегії для генерації тексту з триграмною моделлю\n",
    "ngram_model_top_k = NgramModelWithTopK(n=3)\n",
    "ngram_model_top_k.train(train_text)\n",
    "\n",
    "# Генерація тексту з top-5 стратегією\n",
    "generated_text_top_k = ngram_model_top_k.generate_text_with_top_k(length=20, k=5)\n",
    "generated_text_top_k\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:05:23.509171Z",
     "start_time": "2024-11-06T17:05:22.296298Z"
    }
   },
   "id": "6fac334e7f09f5d7",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "# Функція для генерації тексту\n",
    "def generate_text(n, strategy, k, start_text, max_length):\n",
    "    model = NgramModelWithTopK(n=n)\n",
    "    model.train(train_text)  # Навчання моделі на train_text\n",
    "    \n",
    "    # Токенізуємо початковий текст\n",
    "    start_tokens = start_text.lower().split()\n",
    "    length = max_length\n",
    "    \n",
    "    if strategy == 'top-k':\n",
    "        generated_text = model.generate_text_with_top_k(length=length, k=k)\n",
    "    else:\n",
    "        generated_text = model.generate_text(length=length)  # Greedy\n",
    "    \n",
    "    # Обчислення ентропії\n",
    "    tokens = generated_text.split()\n",
    "    entropies = []\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        context = tuple(tokens[i:i+n-1])\n",
    "        token = tokens[i+n-1]\n",
    "        prob = model.ngram_probability(context, token)\n",
    "        entropies.append(-np.log(prob) if prob > 0 else float('inf'))\n",
    "    \n",
    "    avg_entropy = np.mean(entropies) if entropies else float('inf')\n",
    "    return generated_text, avg_entropy\n",
    "\n",
    "# Налаштування Gradio інтерфейсу\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Генерація тексту за допомогою N-грамної моделі\")\n",
    "    n = gr.Slider(3, 10, step=1, label=\"Виберіть N для моделі\", value=3)\n",
    "    strategy = gr.Radio([\"greedy\", \"top-k\"], label=\"Виберіть стратегію генерації\")\n",
    "    k = gr.Slider(1, 20, step=1, label=\"Виберіть значення k для top-k стратегії\", value=5)\n",
    "    start_text = gr.Textbox(label=\"Початковий текст\")\n",
    "    max_length = gr.Slider(5, 50, step=1, label=\"Максимальна довжина згенерованого тексту\", value=20)\n",
    "    \n",
    "    # Кнопка генерації та виведення результатів\n",
    "    generate_button = gr.Button(\"Згенерувати текст\")\n",
    "    output_text = gr.Textbox(label=\"Згенерований текст\")\n",
    "    entropy = gr.Number(label=\"Ентропія згенерованого тексту\")\n",
    "    \n",
    "    # Зв'язуємо функцію генерації з інтерфейсом\n",
    "    generate_button.click(generate_text, inputs=[n, strategy, k, start_text, max_length], outputs=[output_text, entropy])\n",
    "\n",
    "# Запуск демо-додатку\n",
    "demo.launch()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:05:33.439389Z",
     "start_time": "2024-11-06T17:05:23.509171Z"
    }
   },
   "id": "9cf2408a1baf2853",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "to be or"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ff130e96cbf798d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "wherefore art thou"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fad93cb023355a79"
  },
  {
   "cell_type": "markdown",
   "source": [
    "all the world's a stage"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69c573d179bc3d5b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "love looks not"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2105842979ce9c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:05:33.442487Z",
     "start_time": "2024-11-06T17:05:33.440397Z"
    }
   },
   "id": "be41e5a2e8fdd242",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "abf32841408b38de"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.lm import Laplace\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.util import ngrams\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:08:01.961345Z",
     "start_time": "2024-11-06T17:08:01.958283Z"
    }
   },
   "id": "381c089f3f7974b0",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_text_tokens = [list(line) for line in train_text]\n",
    "test_text_tokens = [list(line) for line in test_text]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:08:02.617195Z",
     "start_time": "2024-11-06T17:08:02.565812Z"
    }
   },
   "id": "2ded2d1a3c0661df",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_ngram_model(n, train_text_tokens):\n",
    "    # Підготовка n-грам та тренувальних даних\n",
    "    train_data, padded_vocab = padded_everygram_pipeline(n, train_text_tokens)\n",
    "    # Використання згладжування Лапласа\n",
    "    model = Laplace(n)\n",
    "    model.fit(train_data, padded_vocab)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:08:03.125153Z",
     "start_time": "2024-11-06T17:08:03.121005Z"
    }
   },
   "id": "64f4928174b3b251",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_text_nltk(model, n, start_text, max_length=15, strategy=\"top-k\", k=5):\n",
    "    # Токенізація початкового тексту\n",
    "    context = start_text.split()\n",
    "    generated = context.copy()\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        # Створення контексту для n-грамної моделі\n",
    "        context_ngram = list(ngrams(context, n - 1))[-1] if len(context) >= n - 1 else context\n",
    "        \n",
    "        if strategy == \"greedy\":\n",
    "            # Найімовірніший наступний токен\n",
    "            next_word = model.generate(text_seed=context_ngram)\n",
    "        elif strategy == \"top-k\":\n",
    "            # Отримання топ-k токенів і їх ймовірностей\n",
    "            candidates = [(word, model.score(word, context_ngram)) for word in model.vocab]\n",
    "            candidates = sorted(candidates, key=lambda x: x[1], reverse=True)[:k]\n",
    "            words, probabilities = zip(*candidates)\n",
    "            probabilities = np.array(probabilities) / sum(probabilities)\n",
    "            next_word = np.random.choice(words, p=probabilities)\n",
    "        \n",
    "        if next_word == '</s>':\n",
    "            break\n",
    "        generated.append(next_word)\n",
    "        context.append(next_word)\n",
    "        \n",
    "    return ' '.join(generated)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:08:03.705661Z",
     "start_time": "2024-11-06T17:08:03.699123Z"
    }
   },
   "id": "4f726411463e55ee",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: to be or <s> i am a gentleman\n"
     ]
    }
   ],
   "source": [
    "# Приклад використання\n",
    "n = 3  # наприклад, триграма\n",
    "model = train_ngram_model(n, train_text_tokens)\n",
    "generated_text = generate_text_nltk(model, n, start_text=\"to be or\", max_length=15, strategy=\"top-k\", k=5)\n",
    "print(\"Generated Text:\", generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:08:16.011032Z",
     "start_time": "2024-11-06T17:08:05.060244Z"
    }
   },
   "id": "f8e7fecc295fd231",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "38cbdc0e1abb9dd"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: to be or to not not <s> be to not not or <s> be not be to be\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.lm import Laplace\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.util import ngrams\n",
    "import numpy as np\n",
    "\n",
    "# Підготовка тексту для навчання (токенізація)\n",
    "def prepare_data(train_text_tokens, n):\n",
    "    train_data, padded_vocab = padded_everygram_pipeline(n, train_text_tokens)\n",
    "    return train_data, padded_vocab\n",
    "\n",
    "# Функція для створення та навчання n-грамної моделі\n",
    "def train_ngram_model(n, train_text_tokens):\n",
    "    train_data, padded_vocab = prepare_data(train_text_tokens, n)\n",
    "    model = Laplace(n)\n",
    "    model.fit(train_data, padded_vocab)\n",
    "    return model\n",
    "\n",
    "# Функція для генерації тексту за top-k стратегією\n",
    "def generate_text_with_top_k(model, n, start_text, max_length=15, k=5):\n",
    "    # Початковий контекст\n",
    "    context = start_text.split()\n",
    "    generated = context.copy()\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        # Формуємо контекст для n-грамної моделі\n",
    "        context_ngram = tuple(context[-(n-1):]) if len(context) >= n - 1 else tuple(context)\n",
    "        \n",
    "        # Отримуємо топ-k токени з їх ймовірностями\n",
    "        candidates = [(word, model.score(word, context_ngram)) for word in model.vocab]\n",
    "        candidates = sorted(candidates, key=lambda x: x[1], reverse=True)[:k]\n",
    "        \n",
    "        # Якщо жодного кандидата не знайдено, завершуємо генерацію\n",
    "        if not candidates:\n",
    "            break\n",
    "        \n",
    "        words, probabilities = zip(*candidates)\n",
    "        probabilities = np.array(probabilities) / sum(probabilities)\n",
    "        \n",
    "        # Випадковий вибір наступного токена з top-k\n",
    "        next_word = np.random.choice(words, p=probabilities)\n",
    "        \n",
    "        if next_word == '</s>':  # Завершення при досягненні кінця речення\n",
    "            break\n",
    "        \n",
    "        generated.append(next_word)\n",
    "        context.append(next_word)\n",
    "    \n",
    "    return ' '.join(generated)\n",
    "\n",
    "# Приклад використання\n",
    "train_text_tokens = [list(line.split()) for line in [\"to be or not to be\", \"that is the question\"]]\n",
    "n = 3  # Триграмна модель\n",
    "model = train_ngram_model(n, train_text_tokens)\n",
    "\n",
    "# Генеруємо текст із початковими словами \"to be or\" і top-5 стратегією\n",
    "generated_text = generate_text_with_top_k(model, n, start_text=\"to be or\", max_length=15, k=5)\n",
    "print(\"Generated Text:\", generated_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:09:07.966484Z",
     "start_time": "2024-11-06T17:09:07.867546Z"
    }
   },
   "id": "ee8084cb8531c699",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import nltk\n",
    "from nltk.lm import Laplace\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.util import ngrams\n",
    "import numpy as np\n",
    "\n",
    "# Функція для підготовки та навчання моделі\n",
    "def train_ngram_model(n, train_text_tokens):\n",
    "    train_data, padded_vocab = padded_everygram_pipeline(n, train_text_tokens)\n",
    "    model = Laplace(n)\n",
    "    model.fit(train_data, padded_vocab)\n",
    "    return model\n",
    "\n",
    "# Функція для генерації тексту за top-k та greedy стратегіями\n",
    "def generate_text(model, n, start_text, max_length=15, strategy=\"top-k\", k=5):\n",
    "    context = start_text.split()\n",
    "    generated = context.copy()\n",
    "    entropies = []\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        context_ngram = tuple(context[-(n-1):]) if len(context) >= n - 1 else tuple(context)\n",
    "        \n",
    "        if strategy == \"greedy\":\n",
    "            next_word = model.generate(text_seed=context_ngram)\n",
    "        elif strategy == \"top-k\":\n",
    "            candidates = [(word, model.score(word, context_ngram)) for word in model.vocab]\n",
    "            candidates = sorted(candidates, key=lambda x: x[1], reverse=True)[:k]\n",
    "            if not candidates:\n",
    "                break\n",
    "            words, probabilities = zip(*candidates)\n",
    "            probabilities = np.array(probabilities) / sum(probabilities)\n",
    "            next_word = np.random.choice(words, p=probabilities)\n",
    "        \n",
    "        if next_word == '</s>':\n",
    "            break\n",
    "        generated.append(next_word)\n",
    "        context.append(next_word)\n",
    "        \n",
    "        # Обчислення ентропії для кожного обраного токена\n",
    "        prob = model.score(next_word, context_ngram)\n",
    "        if prob > 0:\n",
    "            entropies.append(-np.log(prob))\n",
    "    \n",
    "    avg_entropy = np.mean(entropies) if entropies else float('inf')\n",
    "    return ' '.join(generated), avg_entropy\n",
    "\n",
    "# Підготовка навчального тексту\n",
    "train_text_tokens = [list(line.split()) for line in [\"to be or not to be\", \"that is the question\"]]\n",
    "\n",
    "# Створення Gradio інтерфейсу\n",
    "def gradio_app(start_text, n, max_length, strategy, k):\n",
    "    model = train_ngram_model(n, train_text_tokens)\n",
    "    generated_text, avg_entropy = generate_text(model, n, start_text, max_length, strategy, k)\n",
    "    return generated_text, avg_entropy\n",
    "\n",
    "# Налаштування інтерфейсу\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Генерація тексту за допомогою N-грамної моделі\")\n",
    "    start_text = gr.Textbox(label=\"Початковий текст\")\n",
    "    n = gr.Slider(3, 10, step=1, label=\"Виберіть N для моделі\", value=3)\n",
    "    max_length = gr.Slider(5, 50, step=1, label=\"Максимальна довжина згенерованого тексту\", value=20)\n",
    "    strategy = gr.Radio([\"greedy\", \"top-k\"], label=\"Виберіть стратегію генерації\")\n",
    "    k = gr.Slider(1, 20, step=1, label=\"Виберіть значення k для top-k стратегії\", value=5)\n",
    "    \n",
    "    generate_button = gr.Button(\"Згенерувати текст\")\n",
    "    output_text = gr.Textbox(label=\"Згенерований текст\")\n",
    "    entropy = gr.Number(label=\"Ентропія згенерованого тексту\")\n",
    "    \n",
    "    generate_button.click(gradio_app, inputs=[start_text, n, max_length, strategy, k], outputs=[output_text, entropy])\n",
    "\n",
    "# Запуск Gradio демо\n",
    "demo.launch()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:11:23.424047Z",
     "start_time": "2024-11-06T17:11:22.812439Z"
    }
   },
   "id": "eb0f8f20e431197",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "773f5b62ee77309b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
